{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10972 entries, 0 to 10971\n",
      "Data columns (total 8 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   GIF ID                10972 non-null  object\n",
      " 1   Web Archive Link      10972 non-null  object\n",
      " 2   MD5 Hash              10972 non-null  object\n",
      " 3   File Size (In Bytes)  10972 non-null  int64 \n",
      " 4   GIPHY Title           10461 non-null  object\n",
      " 5   Import Date           10656 non-null  object\n",
      " 6   Trending Date         10656 non-null  object\n",
      " 7   Description           2463 non-null   object\n",
      "dtypes: int64(1), object(7)\n",
      "memory usage: 685.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"giphy_with_descriptions.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0_/492vkfd907l731l24rh69fww0000gn/T/ipykernel_38993/3854612851.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  giphy_data['GIPHY Title'] = giphy_data['GIPHY Title'].str.replace(r'\\bGIF\\b', '', regex=True).str.strip()\n"
     ]
    }
   ],
   "source": [
    "giphy_data = df[\n",
    "    df['GIPHY Title'].notnull() & \n",
    "    (df['GIPHY Title'] != '[empty]') & \n",
    "    (df['GIPHY Title'] != 'NA')\n",
    "]\n",
    "giphy_data\n",
    "\n",
    "giphy_data['GIPHY Title'] = giphy_data['GIPHY Title'].str.replace(r'\\bGIF\\b', '', regex=True).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0_/492vkfd907l731l24rh69fww0000gn/T/ipykernel_38993/3930895446.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  giphy_data[\"processed\"] = giphy_data[\"GIPHY Title\"].apply(preprocess_titles_enhanced)\n",
      "/var/folders/0_/492vkfd907l731l24rh69fww0000gn/T/ipykernel_38993/3930895446.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  giphy_data[\"emotion\"] = giphy_data[\"processed\"].apply(lambda x: x[\"emotion\"])\n",
      "/var/folders/0_/492vkfd907l731l24rh69fww0000gn/T/ipykernel_38993/3930895446.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  giphy_data[\"keywords\"] = giphy_data[\"processed\"].apply(lambda x: x[\"keywords\"])\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from textblob import TextBlob\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "# Load spaCy's English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Define an enhanced preprocessing function\n",
    "def preprocess_titles_enhanced(title):\n",
    "    \"\"\"\n",
    "    Enhanced preprocessing for extracting sentiment and keywords from titles.\n",
    "    \"\"\"\n",
    "    if pd.isna(title):\n",
    "        return {\"emotion\": \"unknown\", \"keywords\": []}\n",
    "    \n",
    "    # Clean and tokenize the title using spaCy\n",
    "    doc = nlp(title.lower())\n",
    "    tokens = [token.lemma_ for token in doc if token.is_alpha and token.text not in ENGLISH_STOP_WORDS]\n",
    "    \n",
    "    # Extract sentiment polarity and categorize into emotions\n",
    "    sentiment = TextBlob(title).sentiment.polarity\n",
    "    if sentiment > 0.3:\n",
    "        emotion = \"positive\"\n",
    "    elif sentiment < -0.3:\n",
    "        emotion = \"negative\"\n",
    "    else:\n",
    "        emotion = \"neutral\"\n",
    "    \n",
    "    # Extract keywords by filtering nouns and adjectives\n",
    "    keywords = [token.text for token in doc if token.pos_ in {\"NOUN\", \"ADJ\"}]\n",
    "    \n",
    "    return {\"emotion\": emotion, \"keywords\": keywords}\n",
    "\n",
    "\n",
    "giphy_data[\"processed\"] = giphy_data[\"GIPHY Title\"].apply(preprocess_titles_enhanced)\n",
    "\n",
    "# Extract the processed information into separate columns for display\n",
    "giphy_data[\"emotion\"] = giphy_data[\"processed\"].apply(lambda x: x[\"emotion\"])\n",
    "giphy_data[\"keywords\"] = giphy_data[\"processed\"].apply(lambda x: x[\"keywords\"])\n",
    "\n",
    "# Drop the intermediate 'Processed' column for clarity\n",
    "dataset = giphy_data.drop(columns=['processed'])\n",
    "dataset\n",
    "dataset.to_csv(\"cleangiphy.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cluster\n",
       "0      82\n",
       "1    8637\n",
       "2     869\n",
       "3     692\n",
       "4     181\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Prepare data for clustering\n",
    "# Convert emotions to numerical labels\n",
    "label_encoder = LabelEncoder()\n",
    "emotion_labels = label_encoder.fit_transform(dataset['emotion'])\n",
    "\n",
    "# Vectorize the keywords using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=100, stop_words='english')\n",
    "keywords_vectorized = vectorizer.fit_transform(dataset['keywords'].apply(lambda x: \" \".join(x)))\n",
    "\n",
    "# Combine emotion labels and TF-IDF vectors for clustering\n",
    "from scipy.sparse import hstack\n",
    "features = hstack([keywords_vectorized, emotion_labels.reshape(-1, 1)])\n",
    "\n",
    "# Apply K-Means clustering\n",
    "num_clusters = 5  # Set number of clusters\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42, n_init='auto')\n",
    "dataset['Cluster'] = kmeans.fit_predict(features)\n",
    "\n",
    "# Analyze cluster distribution\n",
    "cluster_summary = dataset.groupby('Cluster').size()\n",
    "\n",
    "cluster_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GIF ID</th>\n",
       "      <th>Web Archive Link</th>\n",
       "      <th>GIPHY Title</th>\n",
       "      <th>emotion</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1003Kuq13ICXDO</td>\n",
       "      <td>http://webarchive.loc.gov/all/20150318155641/https://media.giphy.com/media/1003Kuq13ICXDO/giphy.gif</td>\n",
       "      <td>love happy</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100afL9qoUSWSQ</td>\n",
       "      <td>http://webarchive.loc.gov/all/20150318155641/http://media.giphy.com/media/100afL9qoUSWSQ/giphy.gif</td>\n",
       "      <td>happy new england patriots</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>100buaImlNtEuk</td>\n",
       "      <td>http://webarchive.loc.gov/all/20150318155641/https://media.giphy.com/media/100buaImlNtEuk/giphy.gif</td>\n",
       "      <td>absolutely fabulous</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>103c3dyvMqv624</td>\n",
       "      <td>http://webarchive.loc.gov/all/20150318155641/http://media.giphy.com/media/103c3dyvMqv624/giphy.gif</td>\n",
       "      <td>the good dinosaur  by Disney Pixar</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>103JnbaqvpBFGE</td>\n",
       "      <td>http://webarchive.loc.gov/all/20150318155641/http://media.giphy.com/media/103JnbaqvpBFGE/giphy.gif</td>\n",
       "      <td>excited tiger</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>103wxMOQYiCOjK</td>\n",
       "      <td>http://webarchive.loc.gov/all/20150318155641/http://media.giphy.com/media/103wxMOQYiCOjK/giphy.gif</td>\n",
       "      <td>happy sun</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>107nbr93ZhiUJq</td>\n",
       "      <td>http://webarchive.loc.gov/all/20150318155641/http://media.giphy.com/media/107nbr93ZhiUJq/giphy.gif</td>\n",
       "      <td>cute puppy</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>107w1QelN7fTcA</td>\n",
       "      <td>http://webarchive.loc.gov/all/20150318155641/https://media.giphy.com/media/107w1QelN7fTcA/giphy.gif</td>\n",
       "      <td>unique maggie gyllenhaal</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>108M7gCS1JSoO4</td>\n",
       "      <td>http://webarchive.loc.gov/all/20150318155641/https://media.giphy.com/media/108M7gCS1JSoO4/giphy.gif</td>\n",
       "      <td>valentines day love</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>108OKB1XHmqUI8</td>\n",
       "      <td>http://webarchive.loc.gov/all/20150318155641/https://media.giphy.com/media/108OKB1XHmqUI8/giphy.gif</td>\n",
       "      <td>i love lucy</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             GIF ID  \\\n",
       "3    1003Kuq13ICXDO   \n",
       "8    100afL9qoUSWSQ   \n",
       "10   100buaImlNtEuk   \n",
       "58   103c3dyvMqv624   \n",
       "62   103JnbaqvpBFGE   \n",
       "67   103wxMOQYiCOjK   \n",
       "114  107nbr93ZhiUJq   \n",
       "116  107w1QelN7fTcA   \n",
       "126  108M7gCS1JSoO4   \n",
       "128  108OKB1XHmqUI8   \n",
       "\n",
       "                                                                                        Web Archive Link  \\\n",
       "3    http://webarchive.loc.gov/all/20150318155641/https://media.giphy.com/media/1003Kuq13ICXDO/giphy.gif   \n",
       "8     http://webarchive.loc.gov/all/20150318155641/http://media.giphy.com/media/100afL9qoUSWSQ/giphy.gif   \n",
       "10   http://webarchive.loc.gov/all/20150318155641/https://media.giphy.com/media/100buaImlNtEuk/giphy.gif   \n",
       "58    http://webarchive.loc.gov/all/20150318155641/http://media.giphy.com/media/103c3dyvMqv624/giphy.gif   \n",
       "62    http://webarchive.loc.gov/all/20150318155641/http://media.giphy.com/media/103JnbaqvpBFGE/giphy.gif   \n",
       "67    http://webarchive.loc.gov/all/20150318155641/http://media.giphy.com/media/103wxMOQYiCOjK/giphy.gif   \n",
       "114   http://webarchive.loc.gov/all/20150318155641/http://media.giphy.com/media/107nbr93ZhiUJq/giphy.gif   \n",
       "116  http://webarchive.loc.gov/all/20150318155641/https://media.giphy.com/media/107w1QelN7fTcA/giphy.gif   \n",
       "126  http://webarchive.loc.gov/all/20150318155641/https://media.giphy.com/media/108M7gCS1JSoO4/giphy.gif   \n",
       "128  http://webarchive.loc.gov/all/20150318155641/https://media.giphy.com/media/108OKB1XHmqUI8/giphy.gif   \n",
       "\n",
       "                            GIPHY Title   emotion  Similarity  \n",
       "3                            love happy  positive         0.0  \n",
       "8            happy new england patriots  positive         0.0  \n",
       "10                  absolutely fabulous  positive         0.0  \n",
       "58   the good dinosaur  by Disney Pixar  positive         0.0  \n",
       "62                        excited tiger  positive         0.0  \n",
       "67                            happy sun  positive         0.0  \n",
       "114                          cute puppy  positive         0.0  \n",
       "116            unique maggie gyllenhaal  positive         0.0  \n",
       "126                 valentines day love  positive         0.0  \n",
       "128                         i love lucy  positive         0.0  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Function to process query\n",
    "def process_query(query):\n",
    "    # Use TextBlob for sentiment analysis to extract emotion from query\n",
    "    sentiment = TextBlob(query).sentiment\n",
    "    query_emotion = \"positive\" if sentiment.polarity > 0 else \"negative\" if sentiment.polarity < 0 else \"neutral\"\n",
    "    \n",
    "    # Vectorize the query keywords using the same vectorizer\n",
    "    query_keywords_vector = vectorizer.transform([query])\n",
    "    \n",
    "    return query_emotion, query_keywords_vector\n",
    "\n",
    "# Function to perform retrieval\n",
    "def retrieve_gifs(query, top_n=10):\n",
    "    # Process the query\n",
    "    query_emotion, query_keywords_vector = process_query(query)\n",
    "    \n",
    "    # Match clusters by emotion similarity\n",
    "    matching_clusters = dataset[dataset['emotion'] == query_emotion]\n",
    "    \n",
    "    if matching_clusters.empty:\n",
    "        return \"No matching clusters found for the specified emotion.\"\n",
    "\n",
    "    # Compute cosine similarity for keywords within the matching clusters\n",
    "    matching_keywords_vectors = vectorizer.transform(\n",
    "        matching_clusters['keywords'].apply(lambda x: \" \".join(x))\n",
    "    )\n",
    "    similarity_scores = cosine_similarity(query_keywords_vector, matching_keywords_vectors).flatten()\n",
    "    \n",
    "    # Add similarity scores to the dataset\n",
    "    matching_clusters = matching_clusters.copy()\n",
    "    matching_clusters['Similarity'] = similarity_scores\n",
    "    \n",
    "    # Rank by similarity score and select top N results\n",
    "    top_results = matching_clusters.nlargest(top_n, 'Similarity')\n",
    "    return top_results[['GIF ID', 'Web Archive Link', 'GIPHY Title', 'emotion', 'Similarity']]\n",
    "\n",
    "# Example Query\n",
    "query_example = \"Confident\"\n",
    "\n",
    "results = retrieve_gifs(query_example)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GIF ID</th>\n",
       "      <th>Web Archive Link</th>\n",
       "      <th>GIPHY Title</th>\n",
       "      <th>emotion</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6783</th>\n",
       "      <td>2QHLYZFJgjsFq</td>\n",
       "      <td>http://webarchive.loc.gov/all/20150318155641/https://media.giphy.com/media/2QHLYZFJgjsFq/giphy.gif</td>\n",
       "      <td>happy cat</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7129</th>\n",
       "      <td>33OrjzUFwkwEg</td>\n",
       "      <td>http://webarchive.loc.gov/all/20150318155641/http://media.giphy.com/media/33OrjzUFwkwEg/giphy.gif</td>\n",
       "      <td>happy cat</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7279</th>\n",
       "      <td>3C7wcZZWGf2Cs</td>\n",
       "      <td>http://webarchive.loc.gov/all/20150318155641/http://media.giphy.com/media/3C7wcZZWGf2Cs/giphy.gif</td>\n",
       "      <td>happy cat</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1841</th>\n",
       "      <td>124if4JhjDwGHu</td>\n",
       "      <td>http://webarchive.loc.gov/all/20150318155641/https://media.giphy.com/media/124if4JhjDwGHu/giphy.gif</td>\n",
       "      <td>happy birthday cat</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.723354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4000</th>\n",
       "      <td>1DTBGm5Rfgymk</td>\n",
       "      <td>http://webarchive.loc.gov/all/20150318155641/https://media.giphy.com/media/1DTBGm5Rfgymk/giphy.gif</td>\n",
       "      <td>happy birthday cat</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.723354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6013</th>\n",
       "      <td>26tPgbUUcfS5IWiTm</td>\n",
       "      <td>http://webarchive.loc.gov/all/20150318155641/https://media.giphy.com/media/26tPgbUUcfS5IWiTm/giphy.gif</td>\n",
       "      <td>machines of loving grace cat  by Faith Holland</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.715793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1003Kuq13ICXDO</td>\n",
       "      <td>http://webarchive.loc.gov/all/20150318155641/https://media.giphy.com/media/1003Kuq13ICXDO/giphy.gif</td>\n",
       "      <td>love happy</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.698312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>103wxMOQYiCOjK</td>\n",
       "      <td>http://webarchive.loc.gov/all/20150318155641/http://media.giphy.com/media/103wxMOQYiCOjK/giphy.gif</td>\n",
       "      <td>happy sun</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.698312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>1097v2ZAvP3lVC</td>\n",
       "      <td>http://webarchive.loc.gov/all/20150318155641/https://media.giphy.com/media/1097v2ZAvP3lVC/giphy.gif</td>\n",
       "      <td>happy christina aguilera</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.698312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>10aADbYxnJlc9q</td>\n",
       "      <td>http://webarchive.loc.gov/all/20150318155641/http://media.giphy.com/media/10aADbYxnJlc9q/giphy.gif</td>\n",
       "      <td>happy global warming</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.698312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 GIF ID  \\\n",
       "6783      2QHLYZFJgjsFq   \n",
       "7129      33OrjzUFwkwEg   \n",
       "7279      3C7wcZZWGf2Cs   \n",
       "1841     124if4JhjDwGHu   \n",
       "4000      1DTBGm5Rfgymk   \n",
       "6013  26tPgbUUcfS5IWiTm   \n",
       "3        1003Kuq13ICXDO   \n",
       "67       103wxMOQYiCOjK   \n",
       "130      1097v2ZAvP3lVC   \n",
       "150      10aADbYxnJlc9q   \n",
       "\n",
       "                                                                                            Web Archive Link  \\\n",
       "6783      http://webarchive.loc.gov/all/20150318155641/https://media.giphy.com/media/2QHLYZFJgjsFq/giphy.gif   \n",
       "7129       http://webarchive.loc.gov/all/20150318155641/http://media.giphy.com/media/33OrjzUFwkwEg/giphy.gif   \n",
       "7279       http://webarchive.loc.gov/all/20150318155641/http://media.giphy.com/media/3C7wcZZWGf2Cs/giphy.gif   \n",
       "1841     http://webarchive.loc.gov/all/20150318155641/https://media.giphy.com/media/124if4JhjDwGHu/giphy.gif   \n",
       "4000      http://webarchive.loc.gov/all/20150318155641/https://media.giphy.com/media/1DTBGm5Rfgymk/giphy.gif   \n",
       "6013  http://webarchive.loc.gov/all/20150318155641/https://media.giphy.com/media/26tPgbUUcfS5IWiTm/giphy.gif   \n",
       "3        http://webarchive.loc.gov/all/20150318155641/https://media.giphy.com/media/1003Kuq13ICXDO/giphy.gif   \n",
       "67        http://webarchive.loc.gov/all/20150318155641/http://media.giphy.com/media/103wxMOQYiCOjK/giphy.gif   \n",
       "130      http://webarchive.loc.gov/all/20150318155641/https://media.giphy.com/media/1097v2ZAvP3lVC/giphy.gif   \n",
       "150       http://webarchive.loc.gov/all/20150318155641/http://media.giphy.com/media/10aADbYxnJlc9q/giphy.gif   \n",
       "\n",
       "                                         GIPHY Title   emotion  Similarity  \n",
       "6783                                       happy cat  positive    1.000000  \n",
       "7129                                       happy cat  positive    1.000000  \n",
       "7279                                       happy cat  positive    1.000000  \n",
       "1841                              happy birthday cat  positive    0.723354  \n",
       "4000                              happy birthday cat  positive    0.723354  \n",
       "6013  machines of loving grace cat  by Faith Holland  positive    0.715793  \n",
       "3                                         love happy  positive    0.698312  \n",
       "67                                         happy sun  positive    0.698312  \n",
       "130                         happy christina aguilera  positive    0.698312  \n",
       "150                             happy global warming  positive    0.698312  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from textblob import TextBlob\n",
    "import numpy as np\n",
    "\n",
    "# Fill missing values in titles and descriptions with empty strings\n",
    "dataset['GIPHY Title'] = dataset['GIPHY Title'].fillna('')\n",
    "dataset['Description'] = dataset['Description'].fillna('')\n",
    "\n",
    "# Combine keywords, titles, and descriptions into a single text field for vectorization\n",
    "dataset['combined_text'] = dataset.apply(\n",
    "    lambda row: ' '.join(row['keywords']).replace(\"'\", \"\").replace(\"[\", \"\").replace(\"]\", \"\") +\n",
    "                ' ' + row['GIPHY Title'] + ' ' + row['Description'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Vectorize the combined text using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=500, stop_words='english')\n",
    "combined_vectorized = vectorizer.fit_transform(dataset['combined_text'])\n",
    "\n",
    "# Function to process query with sentiment analysis and vectorization\n",
    "def process_query(query):\n",
    "    # Use TextBlob for sentiment analysis to extract emotion from query\n",
    "    sentiment = TextBlob(query).sentiment\n",
    "    query_emotion = \"positive\" if sentiment.polarity > 0 else \"negative\" if sentiment.polarity < 0 else \"neutral\"\n",
    "    \n",
    "    # Vectorize the query text\n",
    "    query_vector = vectorizer.transform([query])\n",
    "    \n",
    "    return query_emotion, query_vector\n",
    "\n",
    "# Function to perform retrieval based on combined text similarity\n",
    "def retrieve_gifs_fixed(query, top_n=10):\n",
    "    # Process the query\n",
    "    query_emotion, query_vector = process_query(query)\n",
    "    \n",
    "    # Filter dataset by matching emotions\n",
    "    matching_gifs = dataset[dataset['emotion'] == query_emotion]\n",
    "    \n",
    "    if matching_gifs.empty:\n",
    "        return \"No matching GIFs found for the specified emotion.\"\n",
    "    \n",
    "    # Select rows from the sparse matrix corresponding to the filtered dataset\n",
    "    matching_indices = matching_gifs.index.to_numpy()\n",
    "    matching_vectors = combined_vectorized[matching_indices]\n",
    "    \n",
    "    # Compute cosine similarity with the combined text\n",
    "    similarity_scores = cosine_similarity(query_vector, matching_vectors).flatten()\n",
    "    \n",
    "    # Add similarity scores to the filtered dataset\n",
    "    matching_gifs = matching_gifs.copy()\n",
    "    matching_gifs['Similarity'] = similarity_scores\n",
    "    \n",
    "    # Rank by similarity score and select top N results\n",
    "    top_results = matching_gifs.nlargest(top_n, 'Similarity')\n",
    "    return top_results[['GIF ID', 'Web Archive Link', 'GIPHY Title', 'Description', 'emotion', 'Similarity']]\n",
    "\n",
    "# Example Query\n",
    "query_example = \"A happy moment with a cat\"\n",
    "\n",
    "# Retrieve GIFs for the query\n",
    "results = retrieve_gifs(query_example)\n",
    "\n",
    "results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
