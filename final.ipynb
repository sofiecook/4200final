{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10972 entries, 0 to 10971\n",
      "Data columns (total 7 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   GIF ID                10972 non-null  object\n",
      " 1   Web Archive Link      10972 non-null  object\n",
      " 2   MD5 Hash              10972 non-null  object\n",
      " 3   File Size (In Bytes)  10972 non-null  int64 \n",
      " 4   GIPHY Title           10461 non-null  object\n",
      " 5   Import Date           10656 non-null  object\n",
      " 6   Trending Date         10656 non-null  object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 600.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/CookS21/Downloads/giphy.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0_/492vkfd907l731l24rh69fww0000gn/T/ipykernel_48228/3854612851.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  giphy_data['GIPHY Title'] = giphy_data['GIPHY Title'].str.replace(r'\\bGIF\\b', '', regex=True).str.strip()\n"
     ]
    }
   ],
   "source": [
    "giphy_data = df[\n",
    "    df['GIPHY Title'].notnull() & \n",
    "    (df['GIPHY Title'] != '[empty]') & \n",
    "    (df['GIPHY Title'] != 'NA')\n",
    "]\n",
    "giphy_data\n",
    "\n",
    "giphy_data['GIPHY Title'] = giphy_data['GIPHY Title'].str.replace(r'\\bGIF\\b', '', regex=True).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0_/492vkfd907l731l24rh69fww0000gn/T/ipykernel_48228/2530140841.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  giphy_data['Processed'] = giphy_data['GIPHY Title'].apply(preprocess_titles)\n",
      "/var/folders/0_/492vkfd907l731l24rh69fww0000gn/T/ipykernel_48228/2530140841.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  giphy_data['Emotion'] = giphy_data['Processed'].apply(lambda x: x['emotion'])\n",
      "/var/folders/0_/492vkfd907l731l24rh69fww0000gn/T/ipykernel_48228/2530140841.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  giphy_data['Keywords'] = giphy_data['Processed'].apply(lambda x: x['keywords'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GIF ID</th>\n",
       "      <th>Web Archive Link</th>\n",
       "      <th>MD5 Hash</th>\n",
       "      <th>File Size (In Bytes)</th>\n",
       "      <th>GIPHY Title</th>\n",
       "      <th>Import Date</th>\n",
       "      <th>Trending Date</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000eGIbYHercI</td>\n",
       "      <td>http://webarchive.loc.gov/all/20150318155641/h...</td>\n",
       "      <td>245bd1a346bf15da905a7acfd1985d87</td>\n",
       "      <td>82505</td>\n",
       "      <td>slipper</td>\n",
       "      <td>9/21/2013 3:37</td>\n",
       "      <td>1/1/1970 0:00</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[slipper]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000fHsBSKSL6w</td>\n",
       "      <td>http://webarchive.loc.gov/all/20150318155641/h...</td>\n",
       "      <td>a4328e5fcc99015f2cf04d533cadd06d</td>\n",
       "      <td>102564</td>\n",
       "      <td>swag hustling</td>\n",
       "      <td>6/22/2015 5:35</td>\n",
       "      <td>1/12/2016 23:45</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[swag, hustling]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000WjcUQeqOaY</td>\n",
       "      <td>http://webarchive.loc.gov/all/20150318155641/h...</td>\n",
       "      <td>1980e767b94acaf7978886989b755656</td>\n",
       "      <td>48315</td>\n",
       "      <td>jennifer lawrence salute</td>\n",
       "      <td>3/22/2013 11:27</td>\n",
       "      <td>1/1/1970 0:00</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[jennifer, lawrence, salute]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1003Kuq13ICXDO</td>\n",
       "      <td>http://webarchive.loc.gov/all/20150318155641/h...</td>\n",
       "      <td>10b74b1cd9aaabbd259bc736d2be8db5</td>\n",
       "      <td>104921</td>\n",
       "      <td>love happy</td>\n",
       "      <td>3/7/2016 22:08</td>\n",
       "      <td>0000-00-00 00:00:00</td>\n",
       "      <td>positive</td>\n",
       "      <td>[love]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1004D5v8Dbe6cw</td>\n",
       "      <td>http://webarchive.loc.gov/all/20150318155641/h...</td>\n",
       "      <td>ce3d7602047cb9125d42e098a418ece1</td>\n",
       "      <td>45649</td>\n",
       "      <td>visual album beyonce</td>\n",
       "      <td>12/13/2013 14:32</td>\n",
       "      <td>6/20/2014 7:15</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[album, beyonce]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10967</th>\n",
       "      <td>3o85xpNtPp5H1sLMbK</td>\n",
       "      <td>http://webarchive.loc.gov/all/20150318155641/h...</td>\n",
       "      <td>2ecddd73fbf21de12f521ced2370296a</td>\n",
       "      <td>73206</td>\n",
       "      <td>happy come home</td>\n",
       "      <td>4/30/2015 21:28</td>\n",
       "      <td>1/1/1970 0:00</td>\n",
       "      <td>positive</td>\n",
       "      <td>[home]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10968</th>\n",
       "      <td>3o85xpOBewZNIN0QN2</td>\n",
       "      <td>http://webarchive.loc.gov/all/20150318155641/h...</td>\n",
       "      <td>88f6e072d409207e9ce0f5ba6d50f8a3</td>\n",
       "      <td>129256</td>\n",
       "      <td>dance love  by Aron Shay</td>\n",
       "      <td>4/20/2015 8:36</td>\n",
       "      <td>0000-00-00 00:00:00</td>\n",
       "      <td>positive</td>\n",
       "      <td>[dance, love, Aron, Shay]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10969</th>\n",
       "      <td>3o85xpPcXtQmFu88Ra</td>\n",
       "      <td>http://webarchive.loc.gov/all/20150318155641/h...</td>\n",
       "      <td>80efbcc1fcccc1e906b79156e400c809</td>\n",
       "      <td>95407</td>\n",
       "      <td>day drawing  by Doctor Popular</td>\n",
       "      <td>10/2/2015 19:07</td>\n",
       "      <td>0000-00-00 00:00:00</td>\n",
       "      <td>positive</td>\n",
       "      <td>[day, Doctor, Popular]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10970</th>\n",
       "      <td>3o85xpPS95XJLrwO6Q</td>\n",
       "      <td>http://webarchive.loc.gov/all/20150318155641/h...</td>\n",
       "      <td>9bb8dd22c71c0d77e8cbc676b44788f1</td>\n",
       "      <td>256369</td>\n",
       "      <td>pumpkin spice lol  by Lance Ford</td>\n",
       "      <td>10/2/2015 19:43</td>\n",
       "      <td>0000-00-00 00:00:00</td>\n",
       "      <td>positive</td>\n",
       "      <td>[spice, lol, Lance, Ford]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10971</th>\n",
       "      <td>3o85xpRQK3xJB3oHEk</td>\n",
       "      <td>http://webarchive.loc.gov/all/20150318155641/h...</td>\n",
       "      <td>f660ea6f3d4bf99a50d1c134772dfd7a</td>\n",
       "      <td>133556</td>\n",
       "      <td>by Gif Gif A Chance</td>\n",
       "      <td>9/30/2015 11:40</td>\n",
       "      <td>0000-00-00 00:00:00</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[Gif, Gif, A, Chance]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10461 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   GIF ID                                   Web Archive Link  \\\n",
       "0          1000eGIbYHercI  http://webarchive.loc.gov/all/20150318155641/h...   \n",
       "1          1000fHsBSKSL6w  http://webarchive.loc.gov/all/20150318155641/h...   \n",
       "2          1000WjcUQeqOaY  http://webarchive.loc.gov/all/20150318155641/h...   \n",
       "3          1003Kuq13ICXDO  http://webarchive.loc.gov/all/20150318155641/h...   \n",
       "4          1004D5v8Dbe6cw  http://webarchive.loc.gov/all/20150318155641/h...   \n",
       "...                   ...                                                ...   \n",
       "10967  3o85xpNtPp5H1sLMbK  http://webarchive.loc.gov/all/20150318155641/h...   \n",
       "10968  3o85xpOBewZNIN0QN2  http://webarchive.loc.gov/all/20150318155641/h...   \n",
       "10969  3o85xpPcXtQmFu88Ra  http://webarchive.loc.gov/all/20150318155641/h...   \n",
       "10970  3o85xpPS95XJLrwO6Q  http://webarchive.loc.gov/all/20150318155641/h...   \n",
       "10971  3o85xpRQK3xJB3oHEk  http://webarchive.loc.gov/all/20150318155641/h...   \n",
       "\n",
       "                               MD5 Hash  File Size (In Bytes)  \\\n",
       "0      245bd1a346bf15da905a7acfd1985d87                 82505   \n",
       "1      a4328e5fcc99015f2cf04d533cadd06d                102564   \n",
       "2      1980e767b94acaf7978886989b755656                 48315   \n",
       "3      10b74b1cd9aaabbd259bc736d2be8db5                104921   \n",
       "4      ce3d7602047cb9125d42e098a418ece1                 45649   \n",
       "...                                 ...                   ...   \n",
       "10967  2ecddd73fbf21de12f521ced2370296a                 73206   \n",
       "10968  88f6e072d409207e9ce0f5ba6d50f8a3                129256   \n",
       "10969  80efbcc1fcccc1e906b79156e400c809                 95407   \n",
       "10970  9bb8dd22c71c0d77e8cbc676b44788f1                256369   \n",
       "10971  f660ea6f3d4bf99a50d1c134772dfd7a                133556   \n",
       "\n",
       "                            GIPHY Title       Import Date  \\\n",
       "0                               slipper    9/21/2013 3:37   \n",
       "1                         swag hustling    6/22/2015 5:35   \n",
       "2              jennifer lawrence salute   3/22/2013 11:27   \n",
       "3                            love happy    3/7/2016 22:08   \n",
       "4                  visual album beyonce  12/13/2013 14:32   \n",
       "...                                 ...               ...   \n",
       "10967                   happy come home   4/30/2015 21:28   \n",
       "10968          dance love  by Aron Shay    4/20/2015 8:36   \n",
       "10969    day drawing  by Doctor Popular   10/2/2015 19:07   \n",
       "10970  pumpkin spice lol  by Lance Ford   10/2/2015 19:43   \n",
       "10971               by Gif Gif A Chance   9/30/2015 11:40   \n",
       "\n",
       "             Trending Date   Emotion                      Keywords  \n",
       "0            1/1/1970 0:00   neutral                     [slipper]  \n",
       "1          1/12/2016 23:45   neutral              [swag, hustling]  \n",
       "2            1/1/1970 0:00   neutral  [jennifer, lawrence, salute]  \n",
       "3      0000-00-00 00:00:00  positive                        [love]  \n",
       "4           6/20/2014 7:15   neutral              [album, beyonce]  \n",
       "...                    ...       ...                           ...  \n",
       "10967        1/1/1970 0:00  positive                        [home]  \n",
       "10968  0000-00-00 00:00:00  positive     [dance, love, Aron, Shay]  \n",
       "10969  0000-00-00 00:00:00  positive        [day, Doctor, Popular]  \n",
       "10970  0000-00-00 00:00:00  positive     [spice, lol, Lance, Ford]  \n",
       "10971  0000-00-00 00:00:00   neutral         [Gif, Gif, A, Chance]  \n",
       "\n",
       "[10461 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Define a preprocessing function for extracting sentiment and keywords\n",
    "def preprocess_titles(title):\n",
    "    if pd.isna(title):\n",
    "        return {\"emotion\": \"neutral\", \"keywords\": []}\n",
    "    \n",
    "    # Perform sentiment analysis on the title\n",
    "    sentiment = TextBlob(title).sentiment\n",
    "    emotion = \"positive\" if sentiment.polarity > 0 else \"negative\" if sentiment.polarity < 0 else \"neutral\"\n",
    "    \n",
    "    # Extract keywords (simple example: nouns from the title)\n",
    "    keywords = [word for word, tag in TextBlob(title).tags if tag.startswith('NN')]\n",
    "    \n",
    "    return {\"emotion\": emotion, \"keywords\": keywords}\n",
    "\n",
    "# Apply preprocessing to the GIPHY titles\n",
    "giphy_data['Processed'] = giphy_data['GIPHY Title'].apply(preprocess_titles)\n",
    "giphy_data['Emotion'] = giphy_data['Processed'].apply(lambda x: x['emotion'])\n",
    "giphy_data['Keywords'] = giphy_data['Processed'].apply(lambda x: x['keywords'])\n",
    "\n",
    "# Drop the intermediate 'Processed' column for clarity\n",
    "dataset = giphy_data.drop(columns=['Processed'])\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cluster\n",
       "0    1200\n",
       "1    1509\n",
       "2    7614\n",
       "3      21\n",
       "4     117\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Prepare data for clustering\n",
    "# Convert emotions to numerical labels\n",
    "label_encoder = LabelEncoder()\n",
    "emotion_labels = label_encoder.fit_transform(dataset['Emotion'])\n",
    "\n",
    "# Vectorize the keywords using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=100, stop_words='english')\n",
    "keywords_vectorized = vectorizer.fit_transform(dataset['Keywords'].apply(lambda x: \" \".join(x)))\n",
    "\n",
    "# Combine emotion labels and TF-IDF vectors for clustering\n",
    "from scipy.sparse import hstack\n",
    "features = hstack([keywords_vectorized, emotion_labels.reshape(-1, 1)])\n",
    "\n",
    "# Apply K-Means clustering\n",
    "num_clusters = 5  # Set number of clusters\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42, n_init='auto')\n",
    "dataset['Cluster'] = kmeans.fit_predict(features)\n",
    "\n",
    "# Analyze cluster distribution\n",
    "cluster_summary = dataset.groupby('Cluster').size()\n",
    "\n",
    "cluster_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GIF ID</th>\n",
       "      <th>GIPHY Title</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1003Kuq13ICXDO</td>\n",
       "      <td>love happy</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100afL9qoUSWSQ</td>\n",
       "      <td>happy new england patriots</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>100buaImlNtEuk</td>\n",
       "      <td>absolutely fabulous</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>100vEHquJ6YF8c</td>\n",
       "      <td>contemporary art sculpture  by Art21</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>101LwkhoDGH6Jq</td>\n",
       "      <td>real housewives of orange county</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>101xfknlDa4WnC</td>\n",
       "      <td>pretty little liars bloopers</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1025ods881eE7e</td>\n",
       "      <td>fresh off the boat minorities</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1028QpEkAHcNig</td>\n",
       "      <td>new</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>103c3dyvMqv624</td>\n",
       "      <td>the good dinosaur  by Disney Pixar</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>103JnbaqvpBFGE</td>\n",
       "      <td>excited tiger</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            GIF ID                           GIPHY Title   Emotion  Similarity\n",
       "3   1003Kuq13ICXDO                            love happy  positive         0.0\n",
       "8   100afL9qoUSWSQ            happy new england patriots  positive         0.0\n",
       "10  100buaImlNtEuk                   absolutely fabulous  positive         0.0\n",
       "21  100vEHquJ6YF8c  contemporary art sculpture  by Art21  positive         0.0\n",
       "30  101LwkhoDGH6Jq      real housewives of orange county  positive         0.0\n",
       "31  101xfknlDa4WnC          pretty little liars bloopers  positive         0.0\n",
       "36  1025ods881eE7e         fresh off the boat minorities  positive         0.0\n",
       "39  1028QpEkAHcNig                                   new  positive         0.0\n",
       "58  103c3dyvMqv624    the good dinosaur  by Disney Pixar  positive         0.0\n",
       "62  103JnbaqvpBFGE                         excited tiger  positive         0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Function to process query\n",
    "def process_query(query):\n",
    "    # Use TextBlob for sentiment analysis to extract emotion from query\n",
    "    sentiment = TextBlob(query).sentiment\n",
    "    query_emotion = \"positive\" if sentiment.polarity > 0 else \"negative\" if sentiment.polarity < 0 else \"neutral\"\n",
    "    \n",
    "    # Vectorize the query keywords using the same vectorizer\n",
    "    query_keywords_vector = vectorizer.transform([query])\n",
    "    \n",
    "    return query_emotion, query_keywords_vector\n",
    "\n",
    "# Function to perform retrieval\n",
    "def retrieve_gifs(query, top_n=10):\n",
    "    # Process the query\n",
    "    query_emotion, query_keywords_vector = process_query(query)\n",
    "    \n",
    "    # Match clusters by emotion similarity\n",
    "    matching_clusters = dataset[dataset['Emotion'] == query_emotion]\n",
    "    \n",
    "    if matching_clusters.empty:\n",
    "        return \"No matching clusters found for the specified emotion.\"\n",
    "\n",
    "    # Compute cosine similarity for keywords within the matching clusters\n",
    "    matching_keywords_vectors = vectorizer.transform(\n",
    "        matching_clusters['Keywords'].apply(lambda x: \" \".join(x))\n",
    "    )\n",
    "    similarity_scores = cosine_similarity(query_keywords_vector, matching_keywords_vectors).flatten()\n",
    "    \n",
    "    # Add similarity scores to the dataset\n",
    "    matching_clusters = matching_clusters.copy()\n",
    "    matching_clusters['Similarity'] = similarity_scores\n",
    "    \n",
    "    # Rank by similarity score and select top N results\n",
    "    top_results = matching_clusters.nlargest(top_n, 'Similarity')\n",
    "    return top_results[['GIF ID', 'GIPHY Title', 'Emotion', 'Similarity']]\n",
    "\n",
    "# Example Query\n",
    "query_happy_example = \"happy celebration\"\n",
    "query_sad_example = \"sad\"\n",
    "query_sports_celebration = \"excited sports celebration\"\n",
    "happy_results = retrieve_gifs(query_happy_example)\n",
    "sad_results = retrieve_gifs(query_sad_example)\n",
    "sports_results = retrieve_gifs(query_sports_celebration)\n",
    "\n",
    "sports_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
